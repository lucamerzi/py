{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9137.99015279494\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.950\n",
      "Model:                            OLS   Adj. R-squared:                  0.943\n",
      "Method:                 Least Squares   F-statistic:                     129.7\n",
      "Date:                Sat, 09 Feb 2019   Prob (F-statistic):           3.91e-21\n",
      "Time:                        11:46:29   Log-Likelihood:                -421.10\n",
      "No. Observations:                  40   AIC:                             854.2\n",
      "Df Residuals:                      34   BIC:                             864.3\n",
      "Df Model:                           5                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const       1.094e+05   1548.918     70.660      0.000    1.06e+05    1.13e+05\n",
      "x1          -415.3822   1748.552     -0.238      0.814   -3968.867    3138.103\n",
      "x2           333.5778   1746.454      0.191      0.850   -3215.644    3882.800\n",
      "x3          3.573e+04   2547.324     14.025      0.000    3.05e+04    4.09e+04\n",
      "x4           851.3016   1720.699      0.495      0.624   -2645.580    4348.183\n",
      "x5          4519.8828   2398.520      1.884      0.068    -354.495    9394.261\n",
      "==============================================================================\n",
      "Omnibus:                       15.823   Durbin-Watson:                   2.468\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               23.231\n",
      "Skew:                          -1.094   Prob(JB):                     9.03e-06\n",
      "Kurtosis:                       6.025   Cond. No.                         2.98\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.950\n",
      "Model:                            OLS   Adj. R-squared:                  0.944\n",
      "Method:                 Least Squares   F-statistic:                     166.7\n",
      "Date:                Sat, 09 Feb 2019   Prob (F-statistic):           2.87e-22\n",
      "Time:                        11:46:29   Log-Likelihood:                -421.12\n",
      "No. Observations:                  40   AIC:                             852.2\n",
      "Df Residuals:                      35   BIC:                             860.7\n",
      "Df Model:                           4                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const       1.094e+05   1527.449     71.653      0.000    1.06e+05    1.13e+05\n",
      "x1          -550.8618   1576.071     -0.350      0.729   -3750.456    2648.733\n",
      "x2          3.581e+04   2470.255     14.498      0.000    3.08e+04    4.08e+04\n",
      "x3           825.0471   1691.426      0.488      0.629   -2608.731    4258.825\n",
      "x4          4484.9477   2358.387      1.902      0.065    -302.833    9272.729\n",
      "==============================================================================\n",
      "Omnibus:                       16.074   Durbin-Watson:                   2.467\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               24.553\n",
      "Skew:                          -1.086   Prob(JB):                     4.66e-06\n",
      "Kurtosis:                       6.164   Cond. No.                         2.94\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.950\n",
      "Model:                            OLS   Adj. R-squared:                  0.946\n",
      "Method:                 Least Squares   F-statistic:                     227.8\n",
      "Date:                Sat, 09 Feb 2019   Prob (F-statistic):           1.85e-23\n",
      "Time:                        11:46:29   Log-Likelihood:                -421.19\n",
      "No. Observations:                  40   AIC:                             850.4\n",
      "Df Residuals:                      36   BIC:                             857.1\n",
      "Df Model:                           3                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const       1.094e+05   1508.711     72.543      0.000    1.06e+05    1.13e+05\n",
      "x1          3.597e+04   2397.760     15.003      0.000    3.11e+04    4.08e+04\n",
      "x2           760.8842   1660.808      0.458      0.650   -2607.390    4129.159\n",
      "x3          4285.3366   2260.123      1.896      0.066    -298.405    8869.078\n",
      "==============================================================================\n",
      "Omnibus:                       15.557   Durbin-Watson:                   2.481\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               22.539\n",
      "Skew:                          -1.081   Prob(JB):                     1.28e-05\n",
      "Kurtosis:                       5.974   Cond. No.                         2.83\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.950\n",
      "Model:                            OLS   Adj. R-squared:                  0.947\n",
      "Method:                 Least Squares   F-statistic:                     349.0\n",
      "Date:                Sat, 09 Feb 2019   Prob (F-statistic):           9.65e-25\n",
      "Time:                        11:46:29   Log-Likelihood:                -421.30\n",
      "No. Observations:                  40   AIC:                             848.6\n",
      "Df Residuals:                      37   BIC:                             853.7\n",
      "Df Model:                           2                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const       1.094e+05   1492.516     73.330      0.000    1.06e+05    1.12e+05\n",
      "x1          3.643e+04   2162.300     16.846      0.000     3.2e+04    4.08e+04\n",
      "x2          4021.9184   2162.300      1.860      0.071    -359.318    8403.154\n",
      "==============================================================================\n",
      "Omnibus:                       14.666   Durbin-Watson:                   2.518\n",
      "Prob(Omnibus):                  0.001   Jarque-Bera (JB):               20.582\n",
      "Skew:                          -1.030   Prob(JB):                     3.39e-05\n",
      "Kurtosis:                       5.847   Cond. No.                         2.50\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.945\n",
      "Model:                            OLS   Adj. R-squared:                  0.944\n",
      "Method:                 Least Squares   F-statistic:                     652.4\n",
      "Date:                Sat, 09 Feb 2019   Prob (F-statistic):           1.56e-25\n",
      "Time:                        11:46:29   Log-Likelihood:                -423.09\n",
      "No. Observations:                  40   AIC:                             850.2\n",
      "Df Residuals:                      38   BIC:                             853.6\n",
      "Df Model:                           1                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const       1.094e+05   1540.062     71.066      0.000    1.06e+05    1.13e+05\n",
      "x1          3.934e+04   1540.062     25.542      0.000    3.62e+04    4.25e+04\n",
      "==============================================================================\n",
      "Omnibus:                       13.132   Durbin-Watson:                   2.325\n",
      "Prob(Omnibus):                  0.001   Jarque-Bera (JB):               16.254\n",
      "Skew:                          -0.991   Prob(JB):                     0.000295\n",
      "Kurtosis:                       5.413   Cond. No.                         1.00\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "8274.868018225985\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/_encoders.py:368: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/_encoders.py:390: DeprecationWarning: The 'categorical_features' keyword is deprecated in version 0.20 and will be removed in 0.22. You can use the ColumnTransformer instead.\n",
      "  \"use the ColumnTransformer instead.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Sat Aug 25 09:37:54 2018\n",
    "\n",
    "@author: antoine\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "# import statsmodels.regression.linear_model as sm\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# importer le dataset\n",
    "dataset = pd.read_csv(\"50_Startups.csv\")\n",
    "X = dataset.loc[:,\"R&D Spend\":\"State\"].values\n",
    "# X = dataset.drop(columns=\"Profit\").values\n",
    "Y = dataset.loc[:,\"Profit\"].values\n",
    "\n",
    "# Encodage des variables de catégories\n",
    "labelencoder_X = LabelEncoder()\n",
    "X[:, 3] = labelencoder_X.fit_transform(X[:, 3])\n",
    "\n",
    "onehotencoder_X = OneHotEncoder(categorical_features =[3])\n",
    "X = onehotencoder_X.fit_transform(X).toarray()\n",
    "\n",
    "# Pièges des variables factices\n",
    "X = X[:, 1:]\n",
    "\n",
    "# Diviser notre dataset en training set et test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size = 0.2, random_state = 0)\n",
    "\n",
    "# Feature Scaling <=> Normalisation \n",
    "sc_X = StandardScaler()\n",
    "X_train = sc_X.fit_transform(X_train)\n",
    "X_test = sc_X.transform(X_test)\n",
    "\n",
    "# Fittage du modèle de régression\n",
    "regressor = LinearRegression(fit_intercept=True)\n",
    "regressor.fit(X_train, y_train)\n",
    "\n",
    "# Prédiction des résultats\n",
    "y_pred = regressor.predict(X_test)\n",
    "\n",
    "\"\"\"\n",
    "# Stats Models For backward elimination\n",
    "\"\"\"\n",
    "\n",
    "mse = mean_squared_error(y_pred, y_test)\n",
    "print(np.sqrt(mse))\n",
    "\n",
    "X_train1 = sm.add_constant(X_train)\n",
    "regressor_OLS = sm.OLS(endog = y_train, exog = X_train1).fit()\n",
    "\n",
    "X_test1 = sm.add_constant(X_test)\n",
    "y_pred_ols = regressor_OLS.predict(X_test1)\n",
    "\n",
    "print(regressor_OLS.summary())\n",
    "\n",
    "X_opt = X_train1[:, [0,1,3,4,5]]\n",
    "regressor_OLS = sm.OLS(endog = y_train, exog = X_opt).fit()\n",
    "print(regressor_OLS.summary())\n",
    "\n",
    "X_opt = X_train1[:, [0,3,4,5]]\n",
    "regressor_OLS = sm.OLS(endog = y_train, exog = X_opt).fit()\n",
    "print(regressor_OLS.summary())\n",
    "\n",
    "X_opt = X_train1[:, [0,3,5]]\n",
    "regressor_OLS = sm.OLS(endog = y_train, exog = X_opt).fit()\n",
    "print(regressor_OLS.summary())\n",
    "\n",
    "X_opt = X_train1[:, [0,3]]\n",
    "regressor_OLS = sm.OLS(endog = y_train, exog = X_opt).fit()\n",
    "print(regressor_OLS.summary())\n",
    "\n",
    "regressor.fit(X_train[:, [2]], y_train)\n",
    "y_pred_elim = regressor.predict(X_test[:, [2]])\n",
    "mse_elim = mean_squared_error(y_pred_elim, y_test)\n",
    "print(np.sqrt(mse_elim))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
